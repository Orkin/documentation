---
title: Troubleshoot
description: "Everything you need to troubleshoot your application with Qovery"
sidebar_label: hidden
hide_pagination: true
---

<Alert type="info">

In this guide, you'll find common mistakes, and how to resolve them. If you don't find what you need here, [please use the forum](https://discuss.qovery.com/).

</Alert>

This guide is divided into two section:
* Application deployment issues: it contains the common error you may find during the deployment of an application
* Cluster issues: it contains the common error you may find while managing your clusters

# Application deployment issues

## Liveness/Readiness failed, connect: connection refused

If you encounter this kind of error on the Liveness and/or Readiness probe during an application deployment phase:

```bash
Readiness probe failed: dial tcp 100.64.2.230:80: connect: connection refused
Liveness probe failed: dial tcp 100.64.2.230:80: connect: connection refused
```

That means your application may not able to start, or has started but takes too many time to start.

Here are the possible reasons for starting issues you should check:

<Steps headingDepth={3}>
<ol>
<li>

The declared port on Qovery (here 80), does not match your application's opening port. Check your application port, and [set the correct port to your application configuration][docs.using-qovery.configuration.application#ports].

</li>
<li>

Ensure your application is not listening onto localhost (127.0.0.1) or a specific IP. But set it to all interfaces (0.0.0.0).

</li>
<li>

Your application takes too long to start and the liveness probe is flagging your application as unhealthy. Try to grow the [`liveness_probe.initial_delay_seconds` parameter][docs.using-qovery.configuration.advanced-settings], to inform Kubernetes to delay the time before checking your application availability. Set it for example to 120.

</li>
</ol>
</Steps>

## My app is crashing, how do I connect to investigate?

**Goal: You want to connect to your container's application to debug your application**

First, try to use `qovery shell` command from the [Qovery CLI][docs.using-qovery.interface.cli#shell]. It's a safe method to connect to your container and debug your application.

If your app is crashing in the first seconds, you'll lose the connection to your container, making the debug almost impossible, then continue reading.

<Alert type="danger">

Doing this procedure in **PRODUCTION** will lead to downtime. Be sure of what you're doing before going ahead!

</Alert>

Your app is crashing very quickly, here is how to keep the full control of your container:

<Steps headingDepth={3}>
<ol>

<li>

[Temporary delete the application port from your application configuration][docs.using-qovery.configuration.application#ports]. This to avoid Kubernetes to restart the container when the port is not open.

</li>
<li>

Into your Dockerfile, comment your `EXEC` or `ENTRYPOINT` and add a way to make your container sleep. For example:
```bash
#CMD ["npm", "run", "start"]
CMD ["tail", "-f", "/dev/null"]
```

Commit and push your changes to trigger a new deployment (trigger it manually from the Qovery console if it's not the case).

</li>
<li>

Once the deployment done, you can use [qovery shell][docs.using-qovery.interface.cli#shell] command to connect to your container and debug.

<Alert type="success">

Once you've finished debugging, **remember to configure your application port back**. It's mandatory to avoid downtimes during application releases.

</Alert>

</li>
</ol>
</Steps>


## 0/x nodes are available: x insufficient cpu/ram

If you encounter this kind of error during an application deployment phase:

```bash
0/1 nodes are available: 1 Insufficient cpu (or ram).
```

That means that we cannot reserve the necessary resources to deploy your application or database on your cluster due to an insufficient amount of CPU or RAM. Moreover, the cluster auto-scaler cannot be triggered since it has already reached the maximum number of instances for your cluster (valid only for Managed Kubernetes clusters).

Here are the possible solutions you can apply:

* Reduce the resources (CPU/RAM) allocated to your existing/new service. Have a review of the deployed services and see if you can save up some resources by reducing their CPU/RAM setting. If you are using a *K3S (EC2) cluster*, stop your service before changing the settings. Remember to re-deploy the applications when you edit the resource. Have a look at [the resource section for more information][docs.using-qovery.configuration.application#resources].

* Select a bigger instance type for your cluster (in terms of CPU/RAM). By increasing it, it will unlock the deployment of your application (since new resources have been added). Check your [cluster settings][docs.using-qovery.configuration.clusters#managing-your-cluster-settings], and change the instance type of your cluster.

* (only for Managed kubernets clusters) Increase the maximum number of nodes of your cluster. By increasing it, it will allow the cluster autoscaler to add a new node and allow the deployment of your application (since new resources have been added). Check your [cluster settings][docs.using-qovery.configuration.clusters#managing-your-cluster-settings], and increase the maximum number of nodes of your cluster.

<Alert type="info">

Please note that by increasing the number of nodes OR by selecting a bigger instance type you will increase your cloud provider cost. For more information, have a look at our [cluster section][docs.using-qovery.configuration.clusters#what-are-the-different-instance-types-available-when-creating-a-cluster].

</Alert>

Please note that application resource consumption and application resource allocation are not the same. Have a look at [the resource section for more information][docs.using-qovery.configuration.application#resources]

## During a managed database delete, I've this error: SnapshotQuotaExceeded

This errors occurs because Qovery creates a snapshot before the delete of the database. This to avoid a user mistake who delete a database accidentally.

To fix this issue, you have 2 solutions:

<Steps headingDepth={3}>
<ol>
<li>

You certainly have useless snapshots, from old databases or old ones you don't want to keep anymore. Delete them directly from your Cloud Provider web interface. Here is an example on AWS:

* Search for the database service (here RDS)
* Select the Snapshots menu
* Select the snapshots to delete

<p Valign="center">
  <img src="/img/configuration/database/db-snaptshots-quotas-exceed.png" alt="Database snapshots" />
</p>

</li>
<li>

Open a ticket to the Cloud Provider support, and as to raise this limit.

</li>
</ol>
</Steps>

# Cluster issues

## I don't have Qovery access anymore, how could I delete Qovery deployed resources on my AWS account?

Unfortunately, there is no automatic way to do it with Qovery once we don't have access. However, AWS provides an easy way to retrieve those resources, so you can manually perform the delete. To do so, go on the AWS web console, and search for "Resource Groups & Tag Editor" service, then:

<p Valign="center">
  <img src="/img/aws_resource_groups.png" alt="Resource groups search by tag" />
</p>

1. Click on "Create Resource Group".
2. In Tags, enter: "ClusterLongId".
3. In the "Optional Tag value", enter the Qovery cluster ID. If you don't have it, let AWS suggest it for you. If you have Qovery deployed elements remainings, it will propose the Cluster long ID automatically.
4. Click on "Add".
5. You should see the filter with the information you just entered.
6. Click on "Preview groups resources".
7. You'll have all elements deployed by Qovery and you can delete what you want.

# More
You are looking to troubleshoot your application with Qovery? [Read this very short guide][guides.debugging]
